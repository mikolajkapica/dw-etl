# Himalayan Expeditions ETL Pipeline

## Przegld
Pipeline ETL dla danych ekspedycji himalajskich implementuje proces Extract-Transform-Load (ETL) wykorzystujcy framework Dagster. System przetwarza dane z plik贸w CSV oraz API World Bank, transformuje je i aduje do hurtowni danych opartej na architekturze gwiazdy (star schema).

## Dokumentacja zada ETL

###  extraction.py - Ekstrakcja danych 藕r贸dowych

#### `extract_expeditions_data`
**Cel:** aduje dane ekspedycji z pliku CSV i wykonuje podstawow walidacj struktury danych.

**Proces:**
- Odczytuje plik `expeditions.csv` z katalogu danych
- Sprawdza obecno wymaganych kolumn: `EXPID`, `PEAKID`, `YEAR`, `SEASON`
- Raportuje metryki jakoci danych (duplikaty, brakujce wartoci)
- Zwraca surowe dane ekspedycji

**Dane wejciowe:** Plik CSV z danymi ekspedycji
**Dane wyjciowe:** DataFrame z surowymi danymi ekspedycji

#### `extract_members_data`
**Cel:** aduje dane czonk贸w ekspedycji z pliku CSV z walidacj kompletnoci rekord贸w.

**Proces:**
- Odczytuje plik `members.csv`
- Sprawdza wymagane kolumny: `EXPID`, `FNAME`, `LNAME`
- Analizuje jako danych (brakujce imiona, liczba unikalnych ekspedycji)
- Zwraca surowe dane czonk贸w

**Dane wejciowe:** Plik CSV z danymi czonk贸w ekspedycji
**Dane wyjciowe:** DataFrame z surowymi danymi czonk贸w

#### `extract_peaks_data`
**Cel:** aduje dane szczyt贸w g贸rskich z pliku CSV z walidacj identyfikator贸w.

**Proces:**
- Odczytuje plik `peaks.csv`
- Waliduje struktur danych szczyt贸w
- Sprawdza poprawno identyfikator贸w szczyt贸w

**Dane wejciowe:** Plik CSV z danymi szczyt贸w
**Dane wyjciowe:** DataFrame z surowymi danymi szczyt贸w

###  world_bank.py - Integracja danych zewntrznych

#### `extract_world_bank_data`
**Cel:** Pobiera wska藕niki rozwoju kraj贸w z API World Bank dla wzbogacenia analizy ekspedycji.

**Proces:**
- Pobiera dane z World Bank API dla wska藕nik贸w:
  - `NY.GDP.PCAP.CD` - PKB per capita
  - `HD.HCI.OVRL` - Indeks Kapitau Ludzkiego
  - `IT.NET.USER.ZS` - Procent u偶ytkownik贸w Internetu
  - `SH.MED.PHYS.ZS` - Liczba lekarzy na 1000 mieszkac贸w
  - `PV.EST` - Indeks Stabilnoci Politycznej
- Obsuguje paginacj i retry logic
- Normalizuje format danych z API

**Dane wejciowe:** API World Bank
**Dane wyjciowe:** DataFrame z wska藕nikami kraj贸w

#### `clean_world_bank_data`
**Cel:** Czyci i waliduje dane World Bank, stosuje reguy biznesowe dla wska藕nik贸w.

**Proces:**
- Waliduje zakresy wartoci wska藕nik贸w
- Oblicza wska藕nik jakoci danych na podstawie wieku danych
- Usuwa rekordy spoza rozsdnych zakres贸w
- Normalizuje kody kraj贸w

#### `create_dim_country_indicators`
**Cel:** Tworzy wymiar wska藕nik贸w kraj贸w czcy dane ekspedycji z danymi makroekonomicznymi.

**Proces:**
- Agreguje wska藕niki World Bank na poziomie kraj-rok
- Tworzy tabele wymiaru z surogat keys
- czy z krajami wystpujcymi w danych ekspedycji

###  cleaning.py - Oczyszczanie i standaryzacja danych

#### `clean_expeditions_data`
**Cel:** Oczyszcza dane ekspedycji z deduplikacj i standaryzacj format贸w.

**Proces:**
- **Deduplikacja:** Usuwa duplikaty `EXPID` wybierajc rekord z najwy偶sz kompletnoci danych
- **Czyszczenie dat:** Konwertuje pola dat (`SMTDATE`, `BCDATE`, `STDATE`) do formatu datetime
- **Standaryzacja sezon贸w:** Mapuje kody sezon贸w na standardowe wartoci
- **Konwersja numeryczna:** Przeksztaca pola numeryczne (`YEAR`, `HEIGHTM`, `TOTMEMBERS`, etc.)
- **Parsowanie lider贸w:** Ekstraktuje list lider贸w z pola tekstowego `LEADERS`
- **Okrelenie sukcesu:** Tworzy pole `IS_SUCCESS` na podstawie dostpnych wska藕nik贸w

**Dane wejciowe:** Surowe dane ekspedycji
**Dane wyjciowe:** Oczyszczone dane ekspedycji gotowe do transformacji

#### `clean_members_data`
**Cel:** Oczyszcza dane czonk贸w z normalizacj imion i tworzeniem identyfikator贸w.

**Proces:**
- **Czyszczenie imion:** Standaryzuje format imion i nazwisk (proper case)
- **Tworzenie penych imion:** czy `FNAME` i `LNAME` w `FULL_NAME`
- **Normalizacja obywatelstwa:** Standaryzuje kody kraj贸w w `CITIZEN`
- **Konwersja pci:** Mapuje wartoci pci na standardowe kody
- **Generowanie ID:** Tworzy unikalne `MEMBER_ID` dla ka偶dego czonka
- **Walidacja wieku:** Sprawdza poprawno p贸l wiekowych

**Dane wejciowe:** Surowe dane czonk贸w
**Dane wyjciowe:** Oczyszczone dane czonk贸w z dodatkowymi polami

#### `clean_peaks_data`
**Cel:** Oczyszcza dane szczyt贸w z walidacj wysokoci i lokalizacji.

**Proces:**
- Waliduje wysokoci szczyt贸w
- Normalizuje nazwy szczyt贸w
- Sprawdza poprawno koordinat geograficznych
- Standaryzuje kody kraj贸w gospodarzy

**Dane wejciowe:** Surowe dane szczyt贸w
**Dane wyjciowe:** Oczyszczone dane szczyt贸w

###  dimensions.py - Tworzenie tabel wymiar贸w

#### `create_dim_date`
**Cel:** Tworzy wymiar czasu pokrywajcy zakres dat ekspedycji z atrybutami temporalnymi.

**Proces:**
- Okrela zakres dat na podstawie lat ekspedycji (1900 - obecny rok + 5)
- Generuje cigy kalendarz dziennie
- Dodaje atrybuty: rok, kwarta, miesic, dzie roku, dzie tygodnia
- Tworzy pole `Season` na podstawie miesica
- Generuje klucze `DateKey` i `DATE_KEY` dla join贸w

**Dane wejciowe:** Oczyszczone dane ekspedycji (dla zakresu dat)
**Dane wyjciowe:** Kompletny wymiar czasu

#### `create_dim_nationality`
**Cel:** Tworzy wymiar narodowoci ekstraktujc unikalne kraje z ekspedycji i czonk贸w.

**Proces:**
- Ekstraktuje narodowoci z p贸l: `NATION`, `HOST`, `CITIZEN` 
- Deduplikuje i standaryzuje kody kraj贸w
- Mapuje kody kraj贸w na standardowe nazwy (ISO3)
- Dodaje informacje o regionach geograficznych
- Tworzy klucze surogat dla ka偶dego kraju

**Dane wejciowe:** Oczyszczone dane ekspedycji i czonk贸w
**Dane wyjciowe:** Wymiar narodowoci z regionami

#### `create_dim_peak`
**Cel:** Tworzy wymiar szczyt贸w czcy dane szczyt贸w z informacjami o ekspedycjach.

**Proces:**
- czy dane z `peaks.csv` z danymi ekspedycji
- Agreguje statystyki ekspedycji na szczyt
- Dodaje informacje o statusie wspinaczkowym
- Normalizuje nazwy szczyt贸w i wsp贸rzdne

**Dane wejciowe:** Oczyszczone dane szczyt贸w i ekspedycji
**Dane wyjciowe:** Wymiar szczyt贸w z dodatkowymi atrybutami

#### `create_dim_route`
**Cel:** Tworzy wymiar tras wspinaczkowych z kombinacji p贸l ROUTE1-ROUTE4.

**Proces:**
- Kombinuje pola tras (`ROUTE1`, `ROUTE2`, `ROUTE3`, `ROUTE4`)
- Kategoryzuje typ trasy (standardowa, wariantowa, kombinowana)
- Szacuje poziom trudnoci na podstawie nazw tras
- Deduplikuje unikalne kombinacje tras

**Dane wejciowe:** Oczyszczone dane ekspedycji
**Dane wyjciowe:** Wymiar tras z typologi

#### `create_dim_expedition_status`
**Cel:** Tworzy wymiar status贸w ekspedycji na podstawie przyczyn zakoczenia.

**Proces:**
- Ekstraktuje unikalne wartoci z `TERMREASON`
- Kategoryzuje statusy (sukces, niepowodzenie, przerwanie)
- Mapuje przyczyny na opisowe kategorie
- Dodaje flagi sukcesu dla analiz

**Dane wejciowe:** Oczyszczone dane ekspedycji
**Dane wyjciowe:** Wymiar status贸w ekspedycji

#### `create_dim_host_country`
**Cel:** Tworzy wymiar kraj贸w gospodarzy ekspedycji.

**Proces:**
- Ekstraktuje kraje z pola `HOST`
- Standaryzuje nazwy i kody kraj贸w
- Dodaje informacje geograficzne (region, podregion)
- Generuje klucze surogat

**Dane wejciowe:** Oczyszczone dane ekspedycji
**Dane wyjciowe:** Wymiar kraj贸w gospodarzy

#### `create_dim_member`
**Cel:** Tworzy wymiar czonk贸w ekspedycji z atrybutami demograficznymi.

**Proces:**
- Agreguje dane czonk贸w na poziomie osoby
- Tworzy grupy wiekowe na podstawie wieku
- Dodaje informacje o obywatelstwie
- Generuje unikalne klucze czonk贸w

**Dane wejciowe:** Oczyszczone dane czonk贸w
**Dane wyjciowe:** Wymiar czonk贸w

#### `load_dimension_table`
**Cel:** Uniwersalna funkcja adowania wymiar贸w do bazy danych z logik upsert.

**Proces:**
- Implementuje strategi Slowly Changing Dimension (SCD Type 1)
- Por贸wnuje dane z istniejcymi rekordami w bazie
- Aktualizuje zmienione rekordy, wstawia nowe
- Obsuguje bulk operations dla wydajnoci

###  facts.py - Tworzenie tabeli fakt贸w

#### `prepare_fact_expeditions`
**Cel:** Przygotowuje tabel fakt贸w czc dane ekspedycji z czonkami w model member-centric.

**Proces:**
- **Join strategii:** Wykonuje RIGHT JOIN midzy ekspedycjami a wymiarem czonk贸w
- **Denormalizacja:** czy dane ekspedycji z danymi czonk贸w na poziomie EXPID
- **Mapowanie wymiar贸w:** czy klucze surogat z wszystkich wymiar贸w
- **Konstrukcja fakt贸w:** Tworzy rekord dla ka偶dego czonka ka偶dej ekspedycji z:
  - Kluczami wymiar贸w (PeakKey, MemberKey, DateKey, etc.)
  - Atrybutami ekspedycji (rok, sezon, liczba czonk贸w, dugo)
  - Metrykami ekspedycji (sukcesy, mierci, kontuzje)
  - Atrybutami czonka (wiek, rola, u偶ycie tlenu, sukces osobisty)

**Dane wejciowe:** Wszystkie oczyszczone dane + wszystkie wymiary
**Dane wyjciowe:** Tabela fakt贸w w formacie member-centric

#### `load_fact_expeditions`
**Cel:** aduje przygotowan tabel fakt贸w do bazy danych z walidacj integralnoci.

**Proces:**
- Waliduje integralno referentialn z wymiarami
- Wykonuje walidacj biznesow (zakresy dat, wartoci logiczne)
- aduje dane w batches dla wydajnoci
- Tworzy indeksy i statystyki

**Dane wejciowe:** Przygotowana tabela fakt贸w + wyniki adowania wymiar贸w
**Dane wyjciowe:** Status adowania z metrykami

## Architektura hurtowni danych

### G贸wne tabele:

**FACT_Expeditions** - Tabela fakt贸w (member-centric):
- Jeden rekord na czonka ekspedycji
- Zawiera klucze do wszystkich wymiar贸w
- Metryki: sukcesy, mierci, kontuzje, u偶ycie tlenu
- Atrybuty ekspedycji i czonka

**Wymiary:**
- **DIM_Date** - Kalendarz z atrybutami czasu
- **DIM_Peak** - Szczyty z lokalizacj i statusem
- **DIM_Member** - Czonkowie z demografi  
- **DIM_Nationality** - Kraje z regionami
- **DIM_Route** - Trasy z typologi trudnoci
- **DIM_ExpeditionStatus** - Statusy ekspedycji
- **DIM_HostCountry** - Kraje gospodarze
- **DIM_CountryIndicators** - Wska藕niki makroekonomiczne

## Uruchomienie pipeline

### Wymagania
- Python 3.8+
- Dagster
- pandas, sqlalchemy
- SQL Server

### Uruchomienie
```bash
# Instalacja zale偶noci
pip install -r requirements.txt

# Uruchomienie Dagster UI
dagster dev

# Wykonanie job'a
dagster job execute --job himalayan_etl_full_load
```

### Konfiguracja
Pipeline wymaga konfiguracji:
- Poczenia do bazy SQL Server
- cie偶ek do plik贸w CSV
- Parametr贸w API World Bank

## Monitorowanie i logowanie

Pipeline zawiera:
- **Retry policies** - Automatyczne ponawianie operacji
- **Data quality checks** - Walidacja na ka偶dym etapie  
- **Szczeg贸owe logowanie** - Metryki i status ka偶dej operacji
- **Error handling** - Graceful degradation przy bdach

## Rozszerzenia

Pipeline mo偶e by rozszerzony o:
- **Incremental loading** - adowanie przyrostowe (obecnie implementuje full refresh)
- **Data lineage tracking** - ledzenie pochodzenia danych
- **Advanced SCD** - Slowly Changing Dimensions Type 2
- **Real-time streaming** - Przetwarzanie w czasie rzeczywistym

### Aktualny stan implementacji

**Ju偶 zaimplementowane:**
- Basic upsert logic w tabelach wymiar贸w
- CreatedDate/ModifiedDate w schemacie bazy
- Retry policies i error handling
- Data quality checks

**Do implementacji:**
- Timestamp-based incremental extraction
- Delta loading logic
- Watermark tracking
- Change data capture (CDC)